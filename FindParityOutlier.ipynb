{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, LSTM\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "random.seed(87136784)\n",
    "\n",
    "EVEN = 0\n",
    "ODD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_examples(num_examples, min_n, max_n, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Returns a num_examples x (max_n) matrix of random examples.\n",
    "    Each row is an example of a possible list to feed into the network. Generating each example is\n",
    "        done as follows:\n",
    "        \n",
    "        1. size := random size for this list in [min_n, max_n)\n",
    "        2. parity := random choice of even or odd\n",
    "        3. Fill a list with 'size' random numbers of parity 'parity' in range [min_val, max_val)\n",
    "        4. number := a random number of parity opposite of 'parity' in range [min_val, max_val)\n",
    "        5. Overwrite a random position in the list with 'number'\n",
    "        6. Continue to append -1's to the end of the list until it is of size max_n\n",
    "        7. Append an 'ODD' to the end of the list if 'parity' was even, 'EVEN' if odd (since\n",
    "            we are looking for the loner parity)\n",
    "        \n",
    "    num_examples - the number of examples in the dataset\n",
    "    min_n - the minimum possible number of numbers per example (inclusive)\n",
    "    max_n - the maximum possible number of numbers per example (exclusive)\n",
    "    min_val - the minimum possible number (inclusive)\n",
    "    max_val - the maximum possible number (exclusive)\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        new_arr = []\n",
    "        \n",
    "        # The size of this example\n",
    "        size = random.randrange(min_n, max_n)\n",
    "        \n",
    "        # Decide if we will be mainly even or odd\n",
    "        parity = random.choice([EVEN, ODD])\n",
    "        \n",
    "        for j in range(max_n):\n",
    "            \n",
    "            # If we are > size, use -1\n",
    "            if j > size:\n",
    "                new_arr.append(-1)\n",
    "                continue;\n",
    "            \n",
    "            # Otherwise make an even/odd number based on parity\n",
    "            num = random.randrange(min_val, max_val)\n",
    "            if (parity == EVEN and num % 2 != 0) or (parity == ODD and num % 2 == 0):\n",
    "                num += 1\n",
    "            new_arr.append(num)\n",
    "        \n",
    "        # Insert the one outlier parity into a random place\n",
    "        num = random.randrange(min_val, max_val)\n",
    "        if (parity == EVEN and num % 2 == 0) or (parity == ODD and num % 2 != 0):\n",
    "            num += 1\n",
    "        new_arr[random.randrange(0, size)] = num\n",
    "        \n",
    "        # Append the parity value\n",
    "        new_arr.append(EVEN if parity == ODD else ODD)\n",
    "        \n",
    "        ret.append(new_arr)\n",
    "    \n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "\n",
    "def convert_examples(examples, num_bits, return_truth_values=True):\n",
    "    \"\"\"\n",
    "    Takes the input array (a 2D array where each row is a list acting as a single datapoint\n",
    "        for the RNN), and converts it into a 3D array of shape \n",
    "        (examples.shape[0], num_bits, examples.shape[1])\n",
    "        \n",
    "    Each value in each row is converted into a binary array (unless it is a -1, then it is converted\n",
    "        into a row of -1's), and that is set as the values at the axis=1 dimension\n",
    "    \n",
    "    For example:\n",
    "        The array: [[2, 4, 1, 10, 0],\n",
    "                    [1, 6, 7, -1, 1],\n",
    "                    [2, 5, 3, -1, 1],\n",
    "                    [4, 4, 3,  4, 0]]\n",
    "        with num_bits=4 and return_truth_values=True would return the arrays:\n",
    "        \n",
    "        X = \n",
    "        [\n",
    "        \n",
    "        [[0.0, 0.0, 1.0, 0.0],        rows, cols at z=0\n",
    "         [0.0, 0.0, 0.0, 1.0],\n",
    "         [0.0, 0.0, 1.0, 0.0],\n",
    "         [0.0, 1.0, 0.0, 0.0]],\n",
    "         \n",
    "        [[0.0, 1.0, 0.0, 0.0],        rows, cols at z=1\n",
    "         [0.0, 1.0, 1.0, 0.0],\n",
    "         [0.0, 1.0, 0.0, 1.0],\n",
    "         [0.0, 1.0, 0.0, 0.0]],\n",
    "         \n",
    "        [[0.0, 0.0, 0.0, 1.0],        rows, cols at z=2\n",
    "         [0.0, 1.0, 1.0, 1.0],\n",
    "         [0.0, 0.0, 1.0, 1.0],\n",
    "         [0.0, 0.0, 1.0, 1.0]],\n",
    "        \n",
    "        [[ 1.0,  0.0,  1.0,  0.0],    rows, cols at z=3\n",
    "         [-1.0, -1.0, -1.0, -1.0],\n",
    "         [-1.0, -1.0, -1.0, -1.0],\n",
    "         [ 0.0,  1.0,  0.0,  0.0]]\n",
    "         \n",
    "         ]\n",
    "         \n",
    "         and Y = \n",
    "         [0, 1, 1, 0]\n",
    "    \n",
    "    examples - the examples to convert (should be a 'num_examples' by 'max_n' array of ints)\n",
    "    num_bits - the number of bits to use when converting\n",
    "    return_truth_values - if True, then it is assumed that the correct answer for outlying\n",
    "        parity (0 if even, 1 if odd) is the last column in 'examples'. We will then slice\n",
    "        off that column before converting, and return it as the second object in a tuple\n",
    "        \n",
    "        If False, then the values are simply converted and only the X data is returned\n",
    "    \"\"\"\n",
    "    if return_truth_values:\n",
    "        Y = examples[:, -1]\n",
    "        X = np.zeros([examples.shape[0], num_bits, examples.shape[1] - 1])\n",
    "        for i in range(examples.shape[0]):\n",
    "            for j in range(examples.shape[1] - 1):\n",
    "                X[i, :, j] = int_to_bits(examples[i, j], num_bits)\n",
    "        return X, Y\n",
    "    else:\n",
    "        X = np.zeros([examples.shape[0], num_bits, examples.shape[1]])\n",
    "        for i in range(examples.shape[0]):\n",
    "            for j in range(examples.shape[1]):\n",
    "                X[i, :, j] = int_to_bits(examples[i, j], num_bits)\n",
    "        return X\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def int_to_bits(num, num_bits):\n",
    "    \"\"\"\n",
    "    Converts a number to a 1D numpy array of bits of length num_bits. \n",
    "    If num >= 2^num_bits, then an array of all 1's is returned. \n",
    "    If num < 0, then an array of all -1's is returned\n",
    "    \n",
    "    num_bits - the number of bits to use\n",
    "    num - the number to convert\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for negative number\n",
    "    if num < 0:\n",
    "        return np.full([num_bits, ], -1.0)\n",
    "    \n",
    "    # Check for num >= 2^num_bits (IE: not enough bits to store full number)\n",
    "    if num >= 2**num_bits:\n",
    "        return np.full([num_bits, ], 1)\n",
    "    \n",
    "    # Otherwise, do actual binary\n",
    "    ret = [float(c) for c in \"{0:b}\".format(num)]\n",
    "    while len(ret) < num_bits:\n",
    "        ret = [0.0, ] + ret\n",
    "        \n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_in(num):\n",
    "    \"\"\"\n",
    "    Returns the number of bits needed to fully store num\n",
    "    \"\"\"\n",
    "    return math.floor(math.log(num, 2)) + 1\n",
    "\n",
    "\n",
    "def predict_outlier_parity(l):\n",
    "    \"\"\"\n",
    "    Returns 'EVEN' if the parity of the outlying value is even, 'ODD' if odd. Uses an advanced\n",
    "        machine learning AI, implemented as a Recurrent Neural Network, to accurately predict\n",
    "        whether the parity is even or odd.\n",
    "    \n",
    "    The network is a Recurrent Neural Network using an LSTM layer, ending with two FullyConnected\n",
    "        layers, utilizing ReLU activation, dropout, a binary cross-entropy loss function, and the\n",
    "        RMSProp optimizer.\n",
    "    \n",
    "    l - the list to find the outlier's parity in. Should have a length >= 3, and have exactly one\n",
    "        value that is a different parity from the rest\n",
    "    \"\"\"\n",
    "    num_examples = 10000\n",
    "    min_n = 3\n",
    "    max_n = math.ceil(1.1 * len(l)) + 4\n",
    "    min_val = 0\n",
    "    max_val = 2 * max(l)\n",
    "    num_bits = bits_in(max_val)\n",
    "    \n",
    "    print(\"Creating example dataset...\\n\")\n",
    "\n",
    "    a = make_examples(num_examples, min_n, max_n, min_val, max_val)\n",
    "    X, Y = convert_examples(a, num_bits)\n",
    "    \n",
    "    print(\"Building Model...\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=max(256, num_bits), input_shape=(num_bits, max_n), activation=\"relu\"))\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    print(\"\\nTraining Model...\\n\")\n",
    "\n",
    "    model.fit(X, Y, epochs=10, batch_size=32)\n",
    "    \n",
    "    print(\"\\nDone training, converting input list and predicting...\")\n",
    "    \n",
    "    # Convert the input into a list readable to the RNN\n",
    "    testX = []\n",
    "    for i in range(max_n):\n",
    "        try:\n",
    "            testX.append(l[i])\n",
    "        except:\n",
    "            testX.append(-1)\n",
    "    testX = convert_examples(np.reshape(np.array(testX), [1, -1]), num_bits, return_truth_values=False)\n",
    "    \n",
    "    # Predict what the outlier's parity is\n",
    "    p = model.predict(testX)[0]\n",
    "    \n",
    "    # If the value is closer to EVEN than it is ODD, return EVEN, otherwise return ODD\n",
    "    return EVEN if abs(p - EVEN) <= abs(p - ODD) else ODD\n",
    "\n",
    "\n",
    "def predict_outlier_parity_better(l, num_times=5):\n",
    "    \"\"\"\n",
    "    Predicts the outlier's parity even MORE accurately using a group consensus model\n",
    "    \n",
    "    As an added efficiency bonus, we can stop after at least num_times / 2 models have outputted\n",
    "      the same answer. This greatly increases performance since most of the time, the models\n",
    "      agree.\n",
    "      \n",
    "    num_times - the number of times to run the RNN\n",
    "    \"\"\"\n",
    "    num_even = 0\n",
    "    num_odd = 0\n",
    "    for i in range(num_times):\n",
    "        print(\"\\n\\nRunning Model: %d / %d\\n\\n\" % ((i + 1), num_times))\n",
    "        if predict_outlier_parity(l) == EVEN:\n",
    "            print(\"\\n\\nModel Prediction: EVEN\")\n",
    "            num_even += 1\n",
    "        else:\n",
    "            print(\"\\n\\nModel Prediction: ODD\")\n",
    "            num_odd += 1\n",
    "        \n",
    "        if num_even >= math.ceil(num_times / 2.0) or num_odd >= math.ceil(num_times / 2.0):\n",
    "            print(\"\\n\\nOver 50% of the models have agreed, stopping early...\\n\\n\")\n",
    "            break\n",
    "    \n",
    "    return EVEN if num_even > num_odd else ODD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_value(l, num_times=None):\n",
    "    \"\"\"\n",
    "    Finds the value in the given list that has a parity different than the rest. The list should\n",
    "        be at least of length 3, and have only non-negative integers that are all of one parity\n",
    "        (odd/even), with exacly 1 integer that is of the opposite parity (even/odd)\n",
    "    \n",
    "    l - the list of values to find the outlier in\n",
    "    num_times - if num_times is > 1, then predict_outlier_parity_better() will be\n",
    "        called with num_times=num_times, making the results more accurate\n",
    "    \"\"\"\n",
    "    \n",
    "    if num_times is not None and num_times > 1:\n",
    "        parity = predict_outlier_parity_better(l, num_times=num_times)\n",
    "    else:\n",
    "        parity = predict_outlier_parity(l)\n",
    "    print(\"EVEN!\" if parity == EVEN else \"ODD!\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # And now, search through the list finding the first even or odd number based on parity\n",
    "    for v in l:\n",
    "        if (parity == EVEN and v % 2 == 0) or (parity == ODD and v % 2 != 0):\n",
    "            return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running Model: 1 / 3\n",
      "\n",
      "\n",
      "Creating example dataset...\n",
      "\n",
      "Building Model...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               278528    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 291,429\n",
      "Trainable params: 291,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Train on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 0.3563 - accuracy: 0.8753\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0184 - accuracy: 0.9953\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0063 - accuracy: 0.9988\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0139 - accuracy: 0.9985\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0256 - accuracy: 0.9981\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0072 - accuracy: 0.9992\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 8.4862e-04 - accuracy: 0.9996\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0024 - accuracy: 0.9995\n",
      "\n",
      "Done training, converting input list and predicting...\n",
      "\n",
      "\n",
      "Model Prediction: EVEN\n",
      "\n",
      "\n",
      "Running Model: 2 / 3\n",
      "\n",
      "\n",
      "Creating example dataset...\n",
      "\n",
      "Building Model...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               278528    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 291,429\n",
      "Trainable params: 291,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Train on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.1884 - accuracy: 0.9270\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0073 - accuracy: 0.9984\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0079 - accuracy: 0.9988\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0055 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0156 - accuracy: 0.9990\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0033 - accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0052 - accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 1.8744e-04 - accuracy: 0.9999\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 8.5879e-05 - accuracy: 1.0000\n",
      "\n",
      "Done training, converting input list and predicting...\n",
      "\n",
      "\n",
      "Model Prediction: EVEN\n",
      "\n",
      "\n",
      "Over 50% of the models have agreed, stopping early...\n",
      "\n",
      "\n",
      "EVEN!\n",
      "\n",
      "\n",
      "The bad value is: 6\n"
     ]
    }
   ],
   "source": [
    "# The list we are searching through\n",
    "l = [1, 3, 3, 7, 9, 13, 33, 21, 6, 786715]\n",
    "\n",
    "bad_val = find_outlier_value(l, num_times=3)\n",
    "\n",
    "print(\"The bad value is: %d\" % bad_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
